# log:
#   # Log level (NOTSET will log all messages, including those from external libraries) [string]
#   level: "INFO"
#   # Log messages from external libraries [boolean]
#   external: false
# # Sample read length [integer]
# read_length: 150
# # Maximum number of junctions to insert for STAR [integer]
# limitSjdbInsertNsj: 1000000
# # Strandedness of RNA-seq library [string]
# strandedness: "unstranded"
# # Path YAML file with samples - eg [{id: ID, files: [F1, F2]}, ...] [path]
# samples_file: ~
# # Tag identifying the pipeline run (defaults to a timestamp - YYMMDDHHMMSS) [string]
# tag: ~
# Results base directory where output files are copied [path] (REQUIRED)
resultdir: ~
# Working directory where intermediate files are stored [path] (REQUIRED)
workdir: ~
# Log directory [path] (REQUIRED)
logdir: ~
# # Path to config file [path]
# config_file: ~
# executor:
#   # Name of the executor to use [string]
#   name: "subprocess"
#   # Ammount of memory to allocate to jobs started (if supported by the executor) [size]
#   memory: 2000000000
#   # Number of CPUs to allocate to jobs started (if supported by the executor) [integer]
#   cpus: 1
# subsample:
#   # Number of threads to use for subsampling [integer]
#   threads: 12
#   # Code to run before subsampling FASTQ files [string]
#   init: ""
#   # Target number of reads for subsampling (approximate) [integer]
#   target: 100000000
# rnaseq:
#   # Skip nf-core/rnaseq [boolean]
#   skip: false
#   # RNA-seq aligner [string]
#   aligner: ~
#   # Path to RSEM genome index [path]
#   rsem_index: ~
#   # Path to Salmon genome index [path]
#   salmon_index: ~
#   # Path to STAR genome index [path]
#   star_index: ~
#   # Path to genome gene bed file [path]
#   gene_bed: ~
#   # Path to genome gtf file [path]
#   gtf: ~
#   # Path to transcriptome fasta file [path]
#   transcript_fasta: ~
#   # Path to genome fasta file [path]
#   fasta: ~
#   # Genome reference [string]
#   genome: ~
#   # URL to use for nf-core/rnaseq [string]
#   nf_url: "https://github.com/nf-core/rnaseq"
#   # Tag to use for nf-core/rnaseq [string]
#   nf_tag: "3.14.0"
# rnafusion:
#   # Skip nf-core/rnafusion [boolean]
#   skip: false
#   # Minimum number of callers for fusion to be reported [integer]
#   tools_cutoff: 1
#   # Path to rnafusion references [path]
#   genomes_base: ~
#   # URL to use for nf-core/rnafusion [string]
#   nf_url: "https://github.com/nf-core/rnafusion"
#   # Tag to use for nf-core/rnafusion [string]
#   nf_tag: "3.0.1"
# qlucore:
#   # Skip qlucore mapping [boolean]
#   skip: false
#   # Path to STAR-Fusion reference [path]
#   starfusion_ref: ~
#   subsample:
#     # Number of threads to use for subsampling [integer]
#     threads: 12
#     # Code to run before subsampling qlucore BAM files [string]
#     init: ""
#     # Fraction of reads to subsample if calculation fails [number]
#     fallback_fraction: 0.2
#     # Target number of reads for subsampling (approximate) [integer]
#     target: 20000000
# mail:
#   # Send mail [boolean]
#   send: false
#   # Default list of CC recipients [array]
#   cc_addr: ~
#   # Default list of recipients [array]
#   to_addr: ~
#   # Default from address [string]
#   from_addr: ~
#   start:
#     # Subject of the mail (jinja2 template) [string]
#     subject: "{{ config.analysis }} started"
#     # List of files to attach [array]
#     attachments: []
#     # Body of the mail (jinja2 template) [string]
#     body: |
#       # {{ config.analysis }}
# 
#       Analysis has started for {{ samples.unique_ids|length }} sample(s).
# 
#       üîé The following samples are being analyzed:
#       |      ID     |  Run(s)  |
#       | ----------- | -------- |
#       {%- for id_, group in samples.split(by="id") %}
#       | `{{ id_ }}` |
#       {%- for sample in group -%}
#       `{{ sample.run }}`{% if not loop.last %}, {% endif %}
#       {%- endfor -%} |
#       {%- endfor -%}
#   end:
#     # Subject of the mail (jinja2 template) [string]
#     subject: "{{ config.analysis }} finished"
#     # List of files to attach if there are failed samples [array]
#     attachments_failed:
#     - '{config.logdir}/{config.analysis}.{config.tag}.log'
#     # List of files to attach if there are complete samples [array]
#     attachments_complete: []
#     # List of files to attach [array]
#     attachments: []
#     # Body of the mail (jinja2 template, supports markdown) [string]
#     body: |
#       # {{ config.analysis }}
# 
#       {{ samples.unique_ids|length }} sample(s) have been processed.
# 
#       {% if samples.failed -%}
#       ‚ùóÔ∏è Analysis failed for the following samples:
#       |      ID     |  Run(s)  |
#       | ----------- | -------- |
#       {%- for id_, group in samples.failed.split(by="id") %}
#       | `{{ id_ }}` |
#       {%- for sample in group -%}
#       `{{ sample.run }}`{% if not loop.last %}, {% else %} | {% endif %}
#       {%- endfor -%}
#       {%- endfor %}
#       üìã See attached log for more information
#       {% endif -%}
# 
#       {%- if samples.complete -%}
#       ‚úÖ Analysis completed successfully for the following samples:
# 
#       |      ID     |  Run(s)  |
#       | ----------- | -------- |
#       {%- for id_, group in samples.complete.split(by="id") %}
#       | `{{ id_ }}` |
#       {%- for sample in group -%}
#       `{{ sample.run }}`{% if not loop.last %}, {% else %} | {% endif %}
#       {%- endfor -%}
#       {%- endfor %}
# 
#       {%- endif -%}
#   smtp:
#     # SMTP host [string]
#     host: ~
#     # SMTP password [string]
#     password: ~
#     # SMTP username [string]
#     user: ~
#     # Use TLS [boolean]
#     tls: false
#     # SMTP port [integer]
#     port: 25
# rsync:
#   # Overwrite existing results [boolean]
#   overwrite: false
#   # Timeout (in seconds) for files to be available after rsync is complete [integer]
#   timeout: 30
#   # Files larger than this will be copied in a separate job (eg. 100M, 1 GB) [string]
#   large_file_threshold: "100M"
# nextflow:
#   # Threads for nextflow manager [integer]
#   threads: 2
#   # Environment variables that will be passed to the nextflow process [mapping]
#   env: {}
#   # Code to run before running Nextflow (Bash) [string]
#   init: ""
#   # Enable ANSI log [boolean]
#   ansi_log: false
#   # Nextflow workdir [path]
#   workdir: ~
#   # Nextflow profile [string]
#   profile: ~
#   # Nextflow config file [path]
#   config: ~
# hcp:
#   # IRIS credentials file [path]
#   credentials: ~
#   # Number of parallel HCP conenctions [integer]
#   parallel: 4
#   # Temporary directory for fastq files [path]
#   fastq_temp: ~
# slims:
#   # SLIMS URL [string]
#   url: ~
#   # Do not sync data to SLIMS [boolean]
#   dry_run: false
#   # SLIMS criteria for finding records (eg. "cntn_cstm_SecondaryAnalysis equals 1337") [string]
#   criteria: ~
#   # Mapping for creating derived records in SLIMS. Top level key identies the derived record. Use curly braces to acces keys in the 'sample' object, eg. '{sample.id}' [mapping]
#   derive: {}
#   # Use fields from 'slims.map' when matching samples to augment with SLIMS metadata (in addition to 'sample.id') [array]
#   match: []
#   # Fields in slims.map that will be synced to SLIMS in a pre and post hook [array]
#   sync: []
#   # Mapping of keys to SLIMS field(s) (Use json: prefix and dot notation for JSON fields) [mapping]
#   map: {}
#   # SLIMS password [string]
#   password: ~
#   # SLIMS username [string]
#   username: ~
#   novel:
#     # Maximum age of novel records to consider for matchin (eg. '4 days', '1 year') [string]
#     max_age: "1 year"
#     # SLIMS criteria to use for matching novel records (In conjunction with 'slims.criteria') [string]
#     criteria: ~
# grid_engine:
#   # Grid Engine queue [string]
#   queue: "all.q"
#   # Grid Engine parallel environment [string]
#   pe: "mpi"
# unpack:
#   # Code to run before unpacking (Bash) [string]
#   init: ~
#   # Timeout (in seconds) to wait for unpacked file to become available [integer]
#   timeout: 60
#   # Threads for decompression [integer]
#   threads: 40
#   # Code to run after unpacking (Bash) [string]
#   exit: ~
